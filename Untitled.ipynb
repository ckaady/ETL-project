{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'uszipcode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-74600ac182e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Dependencies and Setup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0muszipcode\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSearchEngine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Added 'census' and 'us' to the dependency list to utilize the census wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'uszipcode'"
     ]
    }
   ],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "from uszipcode import SearchEngine\n",
    "\n",
    "# Added 'census' and 'us' to the dependency list to utilize the census wrapper\n",
    "from census import Census\n",
    "from us import states\n",
    "\n",
    "# import api\n",
    "from config import api_key\n",
    "c = Census(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming the data points for easier reading within the loop/API request\n",
    "median_income = 'B19013_001E'\n",
    "employed = 'B23025_004E'\n",
    "unemployed = 'B23025_005E'\n",
    "poverty = 'B17001_002E'\n",
    "poverty_family = 'B17012_002E'\n",
    "age = 'B01002_001E'\n",
    "population = 'B01003_001E'\n",
    "pop_white_alone = 'B02001_002E'\n",
    "pop_black_alone = 'B02001_003E'\n",
    "pop_american_indian_alone = 'B02001_005E'\n",
    "pop_native_hawaiian_alone = 'B02001_006E'\n",
    "pop_two_or_more_races = 'B02001_007E'\n",
    "pop_hispanic_origin = 'B02001_008E'\n",
    "median_home_value = 'B25077_001E'\n",
    "median_gross_rent = 'B25064_001E'\n",
    "commute_time_pub_transit = 'B08136_007E'\n",
    "commute_time_solo_auto = 'B08136_003E'\n",
    "commute_time_walked = 'B08136_011E'\n",
    "transit_solo_auto = 'B08301_003E'\n",
    "transit_pub_transit = 'B08301_010E'\n",
    "transit_walked = 'B08301_019E'\n",
    "transit_other = 'B08101_041E'\n",
    "ed_none = 'B15003_002E'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b331f649e908>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mjoint_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[1;32min\u001b[0m \u001b[0myears\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     med_income = c.acs1.state(('NAME',\n\u001b[0m\u001b[0;32m     10\u001b[0m                               \u001b[0mmedian_income\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                               \u001b[0memployed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "# Starting the for loop to pull in the data fields. Having some trouble naming the four dataframes using the 'year' iterable...\n",
    "# Any thoughts on how to do that?\n",
    "# Run the for loop and it will give you the last dataframe in the series which is '2018', currently. I've formatted the df.\n",
    "# This is almost certainly more information than we need, but I wanted to include data fields that might be relevent.\n",
    "# We can always shrink down the dataframes to the fields we want to focus on.\n",
    "years = [2017]\n",
    "joint_df = pd.DataFrame()\n",
    "for year in years:\n",
    "    med_income = c.acs1.state(('NAME',\n",
    "                              median_income,\n",
    "                              employed,\n",
    "                              unemployed,\n",
    "                              poverty,\n",
    "                              poverty_family,\n",
    "                              age,\n",
    "                              population,\n",
    "                              pop_white_alone,\n",
    "                              pop_black_alone,\n",
    "                              pop_american_indian_alone,\n",
    "                              pop_native_hawaiian_alone,\n",
    "                              pop_two_or_more_races,\n",
    "                              pop_hispanic_origin,\n",
    "                              median_home_value,\n",
    "                              median_gross_rent,\n",
    "                              commute_time_solo_auto,\n",
    "                              commute_time_pub_transit,\n",
    "                              commute_time_walked,\n",
    "                              transit_solo_auto,\n",
    "                              transit_pub_transit,\n",
    "                               # 'year=year' is where the 'year in years' is iterated. You can replace this with whatever\n",
    "                               # year you want, take it out of for loop and run.\n",
    "                              transit_walked),Census.ALL,year=year)\n",
    "    census_df = pd.DataFrame(med_income)\n",
    "    census_df = census_df.rename(columns={\n",
    "        'NAME':'State',\n",
    "        'B19013_001E':'Median Income',\n",
    "        'B23025_004E':'Number Employed',\n",
    "        'B23025_005E':'Number Unemployed',\n",
    "        'B17001_002E':'Number Poverty',\n",
    "        'B17012_002E':'Number Families in Poverty',\n",
    "        'B01002_001E':'Median Age',\n",
    "        'B01003_001E':'Population',\n",
    "        'B02001_002E':'Pop: White Only',\n",
    "        'B02001_003E':'Pop: Black Only',\n",
    "        'B02001_005E':'Pop: American Indian Only',\n",
    "        'B02001_006E':'Pop: Native Hawaiian Only',\n",
    "        'B02001_007E':'Pop: Two or More Races',\n",
    "        'B02001_008E':'Pop: Hispanic Origin',\n",
    "        'B25077_001E':'Median Home Value',\n",
    "        'B25064_001E':'Median Gross Rent',\n",
    "        'B08136_007E':'Commute Time: Solo Auto',\n",
    "        'B08136_003E':'Commute Time: Public Transit',\n",
    "        'B08136_011E':'Commute Time: Walking',\n",
    "        'B08301_003E':'Transit: Solo Auto',\n",
    "        'B08301_010E':'Transit: Public Transit',\n",
    "        'B08301_019E':'Transit: Walking'\n",
    "    })\n",
    "    census_df['Median Income'] = census_df['Median Income'].astype(float).map(\"${:,.2f}\".format)\n",
    "    census_df['Median Home Value'] = census_df['Median Home Value'].astype(float).map(\"${:,.2f}\".format)\n",
    "    census_df['Median Gross Rent'] = census_df['Median Gross Rent'].astype(float).map(\"${:,.2f}\".format)\n",
    "    census_df['Umemployment Rate'] = (census_df['Number Unemployed']/(census_df['Number Employed']+census_df['Number Unemployed'])).astype(float).map(\"{:.2%}\".format)\n",
    "    census_df['Poverty Rate'] = (census_df['Number Poverty']/census_df['Population']).astype(float).map(\"{:.2%}\".format)\n",
    "    census_df['Commute Time: Public Transit'] = (census_df['Commute Time: Public Transit']/census_df['Population'])\n",
    "    census_df['Commute Time: Solo Auto'] = (census_df['Commute Time: Solo Auto']/census_df['Population'])\n",
    "    census_df['Commute Time: Walking'] = (census_df['Commute Time: Walking']/census_df['Population'])\n",
    "    census_df['Transit: Solo Auto'] = (census_df['Transit: Solo Auto']/census_df['Population']).astype(float).map(\"{:.2%}\".format)\n",
    "    census_df['Transit: Public Transit'] = (census_df['Transit: Public Transit']/census_df['Population']).astype(float).map(\"{:.2%}\".format)\n",
    "    census_df['Transit: Walking'] = (census_df['Transit: Walking']/census_df['Population']).astype(float).map(\"{:.2%}\".format)\n",
    "    census_df['Number Employed'] = census_df['Number Employed'].astype(int)\n",
    "    census_df['Number Unemployed'] = census_df['Number Unemployed'].astype(int)\n",
    "    census_df['Number Poverty'] = census_df['Number Poverty'].astype(int)\n",
    "    census_df['Number Families in Poverty'] = census_df['Number Families in Poverty'].astype(int)\n",
    "    census_df['Population'] = census_df['Population'].astype(int)\n",
    "    census_df['Pop: White Only'] = census_df['Pop: White Only'].astype(int)\n",
    "    census_df['Pop: Black Only'] = census_df['Pop: Black Only'].astype(int)\n",
    "    census_df['Pop: American Indian Only'] = census_df['Pop: American Indian Only'].astype(int)\n",
    "    census_df['Pop: Native Hawaiian Only'] = census_df['Pop: Native Hawaiian Only'].astype(int)\n",
    "    census_df['Pop: Two or More Races'] = census_df['Pop: Two or More Races'].astype(int)\n",
    "    census_df['Pop: Hispanic Origin'] = census_df['Pop: Hispanic Origin'].astype(int)\n",
    "    census_df['Pop Rate: White Only'] = (census_df['Pop: White Only']/census_df['Population']).astype(float).map(\"{:.2%}\".format)\n",
    "    census_df['Pop Rate: Black Only'] = (census_df['Pop: Black Only']/census_df['Population']).astype(float).map(\"{:.2%}\".format)\n",
    "    census_df['Pop Rate: American Indian Only'] = (census_df['Pop: American Indian Only']/census_df['Population']).astype(float).map(\"{:.2%}\".format)\n",
    "    census_df['Pop Rate: Native Hawaiian Only'] = (census_df['Pop: Native Hawaiian Only']/census_df['Population']).astype(float).map(\"{:.2%}\".format)\n",
    "    census_df['Pop Rate: Two or More Races'] = (census_df['Pop: Two or More Races']/census_df['Population']).astype(float).map(\"{:.2%}\".format)\n",
    "    census_df['Pop Rate: Hispanic Origin'] = (census_df['Pop: Hispanic Origin']/census_df['Population']).astype(float).map(\"{:.2%}\".format)\n",
    "    census_df.insert(0, 'Year', year)\n",
    "    joint_df = pd.concat([census_df, joint_df])\n",
    "joint_df.to_csv(\"census_data_2017.csv\",encoding=\"utf-8\",index=False)\n",
    "joint_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kittery</td>\n",
       "      <td>US</td>\n",
       "      <td>ME118</td>\n",
       "      <td>43.0899</td>\n",
       "      <td>-70.7415</td>\n",
       "      <td>Kittery Animal Hospital and Creature Comforts LLC</td>\n",
       "      <td>ME</td>\n",
       "      <td>03904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rye</td>\n",
       "      <td>US</td>\n",
       "      <td>NH81</td>\n",
       "      <td>42.9885</td>\n",
       "      <td>-70.8282</td>\n",
       "      <td>Lilac Groves Pampered Pups</td>\n",
       "      <td>NH</td>\n",
       "      <td>03870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rye</td>\n",
       "      <td>US</td>\n",
       "      <td>NH140</td>\n",
       "      <td>42.9885</td>\n",
       "      <td>-70.8282</td>\n",
       "      <td>Northern New England Westie Rescue Inc</td>\n",
       "      <td>NH</td>\n",
       "      <td>03870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stratham</td>\n",
       "      <td>US</td>\n",
       "      <td>NH31</td>\n",
       "      <td>43.0028</td>\n",
       "      <td>-70.9212</td>\n",
       "      <td>NHSPCA</td>\n",
       "      <td>NH</td>\n",
       "      <td>03885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>York</td>\n",
       "      <td>US</td>\n",
       "      <td>ME158</td>\n",
       "      <td>43.1502</td>\n",
       "      <td>-70.6281</td>\n",
       "      <td>The Grateful Dog Animal Rescue</td>\n",
       "      <td>ME</td>\n",
       "      <td>03909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10131</th>\n",
       "      <td>Morris</td>\n",
       "      <td>US</td>\n",
       "      <td>IL717</td>\n",
       "      <td>41.3555</td>\n",
       "      <td>-88.4125</td>\n",
       "      <td>All Those Left Behind Animal Rescue, Inc.</td>\n",
       "      <td>IL</td>\n",
       "      <td>60450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10132</th>\n",
       "      <td>Normal</td>\n",
       "      <td>US</td>\n",
       "      <td>IL806</td>\n",
       "      <td>40.5101</td>\n",
       "      <td>-88.9866</td>\n",
       "      <td>Arrow Dog Rescue</td>\n",
       "      <td>IL</td>\n",
       "      <td>61761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10133</th>\n",
       "      <td>Westville</td>\n",
       "      <td>US</td>\n",
       "      <td>IN23</td>\n",
       "      <td>41.5536</td>\n",
       "      <td>-86.8980</td>\n",
       "      <td>Independent Cat Society</td>\n",
       "      <td>IN</td>\n",
       "      <td>46391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10134</th>\n",
       "      <td>Lansing</td>\n",
       "      <td>US</td>\n",
       "      <td>MI649</td>\n",
       "      <td>42.6813</td>\n",
       "      <td>-84.5757</td>\n",
       "      <td>Purrfect Kitties</td>\n",
       "      <td>MI</td>\n",
       "      <td>48911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10135</th>\n",
       "      <td>Fair Play</td>\n",
       "      <td>US</td>\n",
       "      <td>MO656</td>\n",
       "      <td>37.6333</td>\n",
       "      <td>-93.5749</td>\n",
       "      <td>Hotel McColm</td>\n",
       "      <td>MO</td>\n",
       "      <td>65649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10136 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            city country     id  latitude  longitude  \\\n",
       "0        Kittery      US  ME118   43.0899   -70.7415   \n",
       "1            Rye      US   NH81   42.9885   -70.8282   \n",
       "2            Rye      US  NH140   42.9885   -70.8282   \n",
       "3       Stratham      US   NH31   43.0028   -70.9212   \n",
       "4           York      US  ME158   43.1502   -70.6281   \n",
       "...          ...     ...    ...       ...        ...   \n",
       "10131     Morris      US  IL717   41.3555   -88.4125   \n",
       "10132     Normal      US  IL806   40.5101   -88.9866   \n",
       "10133  Westville      US   IN23   41.5536   -86.8980   \n",
       "10134    Lansing      US  MI649   42.6813   -84.5757   \n",
       "10135  Fair Play      US  MO656   37.6333   -93.5749   \n",
       "\n",
       "                                                    name state    zip  \n",
       "0      Kittery Animal Hospital and Creature Comforts LLC    ME  03904  \n",
       "1                             Lilac Groves Pampered Pups    NH  03870  \n",
       "2                 Northern New England Westie Rescue Inc    NH  03870  \n",
       "3                                                 NHSPCA    NH  03885  \n",
       "4                         The Grateful Dog Animal Rescue    ME  03909  \n",
       "...                                                  ...   ...    ...  \n",
       "10131          All Those Left Behind Animal Rescue, Inc.    IL  60450  \n",
       "10132                                   Arrow Dog Rescue    IL  61761  \n",
       "10133                            Independent Cat Society    IN  46391  \n",
       "10134                                   Purrfect Kitties    MI  48911  \n",
       "10135                                       Hotel McColm    MO  65649  \n",
       "\n",
       "[10136 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "petdata = pd.read_csv(\"resources/petfinder_shelters_with_full_zip.csv\")\n",
    "petdata = petdata.drop(columns=[\"address1\",\"address2\",\"email\",\"phone\"])\n",
    "petdata.to_csv(\"petdata.csv\",encoding=\"utf-8\",index=False)\n",
    "petdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File resources/state_translate.csv does not exist: 'resources/state_translate.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a2682f56288d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstate_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"resources/state_translate.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mstate_ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mJ:\\Anaconda3\\envs\\pythondata\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mJ:\\Anaconda3\\envs\\pythondata\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mJ:\\Anaconda3\\envs\\pythondata\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mJ:\\Anaconda3\\envs\\pythondata\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mJ:\\Anaconda3\\envs\\pythondata\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File resources/state_translate.csv does not exist: 'resources/state_translate.csv'"
     ]
    }
   ],
   "source": [
    "state_ids = pd.read_csv(\"resources/state_translate.csv\")\n",
    "state_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythondata",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
